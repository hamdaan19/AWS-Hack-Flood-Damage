{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be0e891-5ed0-4258-ad11-bbed9f54f929",
   "metadata": {},
   "source": [
    "#### Installing Packages\n",
    "\n",
    "<i>%pip install tensorflow <br>\n",
    "%pip install keras<br>\n",
    "%pip install matplotlib<br>\n",
    "%pip install pillow<br>\n",
    "%pip install tqdm<br>\n",
    "%pip install -U scikit-learn</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4296356c-8099-4e68-ae62-7e2943e2bc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bab1ba-3143-44c8-bd16-d744f75b0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - ETA:  - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [300, 400]\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27be08f0-f0d6-4516-a3b7-961f221b7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 300, 400, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 300, 400, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 300, 400, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 150, 200, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 150, 200, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 150, 200, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 75, 100, 128)      0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 75, 100, 256)      295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 75, 100, 256)      590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 75, 100, 256)      590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 37, 50, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 37, 50, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 37, 50, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 37, 50, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 18, 25, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 18, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 18, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 18, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 9, 12, 512)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 55296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 110594    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,825,282\n",
      "Trainable params: 110,594\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224f199a-037d-4198-9080-caccf0636ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68eddd92-da33-422c-9d26-768c695f438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:28<00:00,  4.69it/s]\n",
      "100%|██████████| 347/347 [01:10<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples is 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "TRAIN_DATA_PATH = \"../../my-datasets/FloodNet Challenge @ EARTHVISION 2021 - Track 1/Train/Classification\"\n",
    "CATEGORIES = [\"Flooded\", \"Non-Flooded\"]\n",
    "train_data_list = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(TRAIN_DATA_PATH, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img_path in tqdm(os.listdir(path)):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(path, img_path))\n",
    "            img = np.array(img.resize((400, 300)))\n",
    "            train_data_list.append([img, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "print(f\"Total number of samples is {len(train_data_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93349148-4503-401f-bc58-d92d69aab911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_data_list)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, label in train_data_list:\n",
    "    X.append(image)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, 300, 400, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "#np.savez_compressed(\"data/X_images\", X, allow_pickle=True)\n",
    "#np.savez_compressed(\"data/y_labels\", y, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbc29fc-a3ad-41c0-8790-1d65f8ccb382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 11:24:05.113607: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172800000 exceeds 10% of free system memory.\n",
      "2022-01-17 11:24:05.302974: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30/30 [==============================] - 12s 141ms/step - loss: 4.5586 - accuracy: 0.9021\n",
      "Epoch 2/3\n",
      "30/30 [==============================] - 4s 142ms/step - loss: 0.1760 - accuracy: 0.9833\n",
      "Epoch 3/3\n",
      "30/30 [==============================] - 4s 142ms/step - loss: 0.3731 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10203bec40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = np.load(\"X_images.npy\")\n",
    "#y = np.load(\"y_labels.npy\")\n",
    "\n",
    "model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b6ef4c-e0c9-4d6e-8597-a3e96883228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 11:24:40.957511: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172800000 exceeds 10% of free system memory.\n",
      "2022-01-17 11:24:41.138035: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#model.evaluate(x=X, y=y, batch_size=16)\n",
    "preds = model.predict(x=X)\n",
    "preds_ = np.argmax(preds, axis=1)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for pred, truth in zip(preds_, y):\n",
    "    if(pred == truth):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "print(f\"Accuracy: {(correct/total)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b1d97-db88-4ef8-9afb-973076b5981a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
